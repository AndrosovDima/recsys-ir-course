{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e588890-60e1-480c-88b5-14347762247a",
   "metadata": {},
   "source": [
    "## Домашнее задание №1\n",
    "\n",
    "### Предлагается реализовать поисковую систему, способную работать с proximity-оператором в запросе\n",
    "\n",
    "#### Ограничения:\n",
    "- В запросах встречаются только операторы OW/N и UW/N, где N - кол-во токенов, которое учитывается операторами\n",
    "- Система должна уметь обрабатывать:\n",
    "  - однотокенные запросы (без proximity-оператора), например: \"молоко\"\n",
    "  - двухтокенные запросы с proximity-оператором между токенами, например: \"молочный OW/1 ломтик\"\n",
    "- Система должна возвращать в ответе на запрос максимум 20 товаров\n",
    "- Весь код должен быть абсолютно воспроизводимым - в режиме \"Run all\"\n",
    "\n",
    "#### Цель - получить работающую поисковую систему с метриками качества на валидационном наборе запросов (прилагается к заданию):\n",
    "- precision > 0.3\n",
    "- recall > 0.4\n",
    "\n",
    "#### Разбалловка за каждый пункт указана ниже, максимальное количество баллов за задание - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9e0c6-dca3-4a45-b8f6-4a5f71e2ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import string\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9d805-62b8-4987-ba6b-b5d6721f20d5",
   "metadata": {},
   "source": [
    "### Дан корпус документов - база товаров с их именами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace129a-0a16-4e4d-871b-3b5332ed4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(\"products_with_names.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfefb46-979a-4016-9a02-ffc7b1c701d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dict = {\n",
    "    doc[1][\"product_id\"]: doc[1][\"name\"] for doc in dataset.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cccb7-d5ae-4db2-9b2c-204ef80db443",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Document:\n",
    "    doc_id: int\n",
    "    name: str\n",
    "\n",
    "\n",
    "documents = [Document(doc_id=doc[1][\"product_id\"], name=doc[1][\"name\"]) for doc in dataset.iterrows()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b65704-8219-490f-a7dc-1d6a880dec2c",
   "metadata": {},
   "source": [
    "### Пример реализации класса обработчика текста\n",
    "\n",
    "Не обязательно использовать его в таком виде, можно реализовать любую обработку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ab044-3477-4894-a405-eb5d3e67acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.symbols_to_replace = {\"ё\": \"е\"}\n",
    "        self.stopwords = set(stopwords.words(\"russian\"))\n",
    "        self.linguist = MorphAnalyzer()\n",
    "\n",
    "    def lowercase_text(self, text: str) -> str:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "\n",
    "    def replace_symbols(self, text: str) -> str:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "\n",
    "    def process_punctuation_simple(self, text: str) -> str:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "\n",
    "    def tokenize_simple(self, text: str) -> list[str]:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "\n",
    "    def remove_stopwords(self, tokenized_text: list[str]) -> list[str]:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "\n",
    "    def lemmatize_token(self, token: str) -> str:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "    \n",
    "    def lemmatize_tokenized_text(self, tokenized_text: list[str]) -> list[str]:\n",
    "        # TODO: add some code here\n",
    "        pass\n",
    "\n",
    "    def process_text(self, text: str) -> list[str]:\n",
    "        text = self.lowercase_text(text)\n",
    "        text = self.replace_symbols(text)\n",
    "        text = self.process_punctuation_simple(text)\n",
    "        text_tokens = self.tokenize_simple(text)\n",
    "        text_tokens = self.remove_stopwords(text_tokens)\n",
    "        return self.lemmatize_tokenized_text(text_tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3564256-1465-4d30-9928-d8acb036021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05e409-7f07-4a4f-8a24-e8895cbc9c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_processed = [(document.doc_id, text_processor.process_text(document.name)) for document in tqdm(documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97adb0f6-0fe5-47a9-8529-d340fa78a794",
   "metadata": {},
   "source": [
    "### (2 балла) Составляем positional inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858ecf4-116a-4c92-8f6a-1bfaec4156f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positional_inverted_index(\n",
    "    documents_processed: list[list[str]]\n",
    ") -> dict[str, list[tuple[int, list[int]]]]:\n",
    "    # TODO: add some code here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8841a-6ed0-4e21-90f3-75f6eb2a434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_inverted_index = create_positional_inverted_index(documents_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef59dd-bc3d-40d0-9eb0-0943d875319e",
   "metadata": {},
   "source": [
    "### (3 балла) Реализация слияния списков, учитывающего позиции токенов в документах и proximity-оператор в запросе, и функции обработки запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c278dd0-4f99-448f-959e-923f35d409ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_posting_lists_with_condition(posting_lists, condition):\n",
    "    # TODO: add some code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623b5ed-29fc-4981-a501-1140ad3753c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_over_positional_inverted_index(\n",
    "    positional_inverted_index: dict[str, list[tuple[int, list[int]]]], \n",
    "    documents_dict: dict[int, str],\n",
    "    query: str,\n",
    "    limit: int = None,\n",
    ") -> list[Document]:\n",
    "    # TODO: add some code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ae7fb-0f1d-4245-abf7-46ceb6fb3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_over_positional_inverted_index(positional_inverted_index, documents_dict, \"картофель\", limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dafba6c-7ad2-4426-8d0b-b873133a1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_over_positional_inverted_index(positional_inverted_index, documents_dict, \"молочный OW/1 ломтик\", limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac65b8-e105-4dd6-af82-2faad14954a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_over_positional_inverted_index(positional_inverted_index, documents_dict, \"уксус UW/2 яблочный\", limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9e1ce-57ae-4983-8451-32616ea28605",
   "metadata": {},
   "source": [
    "### Читаем валидационный набор запросов с позитивными примерами товаров\n",
    "\n",
    "Метрики будут считаться на нем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1250b-e35a-44e1-8f57-f1cd37ec040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_proximity_validation_query_positives = pd.read_parquet(\"result_proximity_validation_query_positives.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e93f3-53ee-4386-86d7-a49ac736ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_proximity_validation_query_positives_dict = {\n",
    "    row[1].query: row[1].products.tolist()\n",
    "    for row in result_proximity_validation_query_positives.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e3f84-0585-471e-87e1-69d09f4dc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths_list: list[list[int]] = []\n",
    "search_results_list: list[list[int]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f327cd-a894-445b-b2da-71d03fa3dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, ground_truth_products in result_proximity_validation_query_positives_dict.items():\n",
    "    ground_truths_list.append(ground_truth_products)\n",
    "    search_results_list.append(\n",
    "        search_over_positional_inverted_index(positional_inverted_index, documents_dict, query, limit=20)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea309ac0-8633-43f7-b537-c00ffaca1aa1",
   "metadata": {},
   "source": [
    "### (3 балла - за соответствие требованиям к метрикам) Посчитаем метрики качества системы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30081490-3b9f-490f-add8-ad4c20eace72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metrics:\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1_score: float\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"precision = {self.precision}\\nrecall = {self.recall}\\nf1_score = {self.f1_score}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec77c6-a025-4e47-92e8-f556270e97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(ground_truth_set, search_results_set):\n",
    "    \n",
    "    # True positives: items that are both in ground truth and search results\n",
    "    tp = len(ground_truth_set.intersection(search_results_set))\n",
    "    \n",
    "    # Precision: tp / (tp + fp)\n",
    "    precision = tp / len(search_results_set) if len(search_results_set) > 0 else 0.0\n",
    "    \n",
    "    # Recall: tp / (tp + fn)\n",
    "    recall = tp / len(ground_truth_set) if len(ground_truth_set) > 0 else 0.0\n",
    "    \n",
    "    # F1-score: harmonic mean of precision and recall\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return Metrics(precision=precision, recall=recall, f1_score=f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b2884-2646-4d32-b798-9e509867bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_metrics(ground_truth_products_lists, search_result_products_lists):\n",
    "    metrics = []\n",
    "    for ground_truth, search in zip(ground_truth_products_lists, search_result_products_lists):\n",
    "        metrics.append(\n",
    "            calculate_metrics(set(ground_truth), set(x.doc_id for x in search))\n",
    "        )\n",
    "    \n",
    "    return Metrics(\n",
    "        precision=np.mean([x.precision for x in metrics]),\n",
    "        recall=np.mean([x.recall for x in metrics]),\n",
    "        f1_score=np.mean([x.f1_score for x in metrics]),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644ff6a-e8c2-47b1-82bc-f86106f91e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_validation_metrics(ground_truths_list, search_results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df23db-7640-4679-a1c3-0627b0fadc98",
   "metadata": {},
   "source": [
    "### (2 балла) Сравнить метрики с поиском по обратному индексу без учета позиций\n",
    "\n",
    "Нужно:\n",
    "- реализовать поисковый движок над обратным индексом без токенопозиций;\n",
    "- посчитать метрики качества (precision, recall) на том же валидационном наборе запросов (игнорируя proximity-операторы);\n",
    "- сравнить метрики с первым подходом и сделать вывод о полезности токенопозиций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e9c0a-10d0-46fd-af3e-9926930c04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add some code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f794738-2dea-4056-97b3-474eea03337a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
