{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1ac091-a435-46fb-8746-c13392c2ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import hnswlib\n",
    "import faiss\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7916abd1-85fc-48d1-8f4f-ea7c89f27f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(\"products_with_names.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d02cc48-00d0-474f-beb9-24bc1bf4b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Document:\n",
    "    document_id: int\n",
    "    document_name: str\n",
    "\n",
    "documents = [Document(document_id=doc[1][\"product_id\"], document_name=doc[1][\"name\"]) for doc in dataset.iterrows() if doc[1][\"name\"] != \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd089f9-bf18-4a33-b707-50936acd5045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(document_id=4036767, document_name='Модуль сменный фильтрующий Аквафор КН, 208731'),\n",
       " Document(document_id=4050873, document_name='Водоочиститель Аквафор модель Кристалл Н, 205963 //с краном'),\n",
       " Document(document_id=4226160, document_name='Развиваем мышление (2-3 года) | Земцова Ольга'),\n",
       " Document(document_id=4644911, document_name='Lacoste Вода парфюмерная Pour Femme 50 мл'),\n",
       " Document(document_id=4788809, document_name='Сменные Кассеты Для Мужской Бритвы Gillette Mach3, с 3 лезвиями, прочнее, чем сталь, для точного бритья, 2 шт')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88ade5f-b0ca-4f9f-82f7-5af36d6b4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTextProcessor:\n",
    "    def __init__(self):\n",
    "        self.symbols_to_replace = {\"ё\": \"е\"}\n",
    "\n",
    "    def lowercase_text(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def replace_symbols(self, text: str) -> str:\n",
    "        for old, new in self.symbols_to_replace.items():\n",
    "            text = text.replace(old, new)\n",
    "        return text\n",
    "\n",
    "    def process_punctuation_simple(self, text: str) -> str:\n",
    "        translation_table = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "        text_without_punc = text.translate(translation_table)\n",
    "        text_without_double_spaces = ' '.join(text_without_punc.split())\n",
    "        return text_without_double_spaces\n",
    "\n",
    "    def process_text(self, text: str) -> str:\n",
    "        text = self.lowercase_text(text)\n",
    "        text = self.replace_symbols(text)\n",
    "        text = self.process_punctuation_simple(text)\n",
    "        return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1520b288-e6f5-4545-8a94-898e44661970",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = SimpleTextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190dad10-e66c-43d1-bbf5-b79ba6cf61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238428/238428 [00:03<00:00, 72133.85it/s]\n"
     ]
    }
   ],
   "source": [
    "documents_processed = [\n",
    "    Document(document.document_id, text_processor.process_text(document.document_name)) \n",
    "    for document in tqdm(documents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55a54bc-44cd-415d-9e3a-ba99495ad523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(document_id=4036767, document_name='модуль сменный фильтрующий аквафор кн 208731'),\n",
       " Document(document_id=4050873, document_name='водоочиститель аквафор модель кристалл н 205963 с краном'),\n",
       " Document(document_id=4226160, document_name='развиваем мышление 2 3 года земцова ольга'),\n",
       " Document(document_id=4644911, document_name='lacoste вода парфюмерная pour femme 50 мл'),\n",
       " Document(document_id=4788809, document_name='сменные кассеты для мужской бритвы gillette mach3 с 3 лезвиями прочнее чем сталь для точного бритья 2 шт')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_processed[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a629e6-52e0-46cd-a803-7b65f5c56632",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f5f18d3-0850-4053-b03c-36a8cb493df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc.document_name for doc in documents_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85b9e3a-9593-4a6e-87c1-a9bdee1784a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"],\n",
    "    vocab_size=10_000,\n",
    "    min_frequency=2,\n",
    "    show_progress=True,\n",
    "    continuing_subword_prefix=\"##\",\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "tokenizer.save(\"bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e11612-401e-4c92-ba26-f092f99e0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7646ddf6-b106-4cdc-b972-76118e8eb07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['мороженое', 'для', 'собак']\n",
      "Token ids: [2326, 195, 566]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"мороженое для собак\")\n",
    "print(f\"Tokens: {encoding.tokens}\")\n",
    "print(f\"Token ids: {encoding.ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440f6b7d-9bf9-4b69-8794-03dbae2f9e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['бритва', 'gillette']\n",
      "Token ids: [3905, 4069]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"бритва gillette\")\n",
    "print(f\"Tokens: {encoding.tokens}\")\n",
    "print(f\"Token ids: {encoding.ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2962ed05-4830-4fa4-a645-a8ceb12cbb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['шампунь', 'мужской', 'nivea', 'men']\n",
      "Token ids: [815, 1278, 3090, 2877]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"шампунь мужской nivea men\")\n",
    "print(f\"Tokens: {encoding.tokens}\")\n",
    "print(f\"Token ids: {encoding.ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f854e07c-12b6-405b-881a-f6e35fa40aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['шампунь', 'мужской', 'nivea', 'men', 'охлажда', '##ющий']\n",
      "Token ids: [815, 1278, 3090, 2877, 7492, 300]\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(\"шампунь мужской nivea men охлаждающий\")\n",
    "print(f\"Tokens: {encoding.tokens}\")\n",
    "print(f\"Token ids: {encoding.ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59960bf5-12d3-4b23-95eb-0f27a0581f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'шампунь мужской nivea men охлажда ##ющий'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eda3e8f-7043-4d13-bde8-4e94c81150ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 10000\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "print(f\"Tokenizer vocab size: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f4b8d-ca21-4e9b-8956-fe26970238f9",
   "metadata": {},
   "source": [
    "## Building DSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646aa8af-e73f-4766-91bb-e8bc0056432d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f11492-3da3-48a5-b04e-e314819eeb96",
   "metadata": {},
   "source": [
    "![title](dssm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba7ad2f-b587-45e8-b95c-0c37fda699a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSM(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int = 256, hidden_dims: list[int] = [512, 256, 128], padding_idx: int = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.padding_idx = padding_idx\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.LayerNorm(input_dim))\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "            input_dim = dim\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        self.ln = nn.LayerNorm(input_dim)\n",
    "        \n",
    "    def forward(self, input_ids: torch.LongTensor):\n",
    "        input_embeddings = self.embedding(input_ids)\n",
    "\n",
    "        input_embeddings_pooled = torch.sum(input_embeddings, dim=1) / torch.sum(input_ids!=self.padding_idx, dim=1, keepdim=True)\n",
    "\n",
    "        mlp_embeddings = self.mlp(input_embeddings_pooled)\n",
    "\n",
    "        return self.ln(mlp_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc567e-37f7-4d48-9e1c-b76c530e6e82",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d399854-9c9a-4484-8ebc-0af0b04a164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_product_positive_interactions = pd.read_parquet(\"query_product_positive_interactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa93ef8-407a-4515-994a-695b1b301529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18121972, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_product_positive_interactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "667e02eb-1b29-43f8-8c2e-0ebd681e1131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>search_query</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9897711</td>\n",
       "      <td>2024-03-16 11:28:10</td>\n",
       "      <td>линзы</td>\n",
       "      <td>ACUVUE Контактные линзы, -3.75, 8.4, 2 недели</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3666669</td>\n",
       "      <td>2024-04-15 13:40:39</td>\n",
       "      <td>линзы -4</td>\n",
       "      <td>ACUVUE Контактные линзы, -3.75, 8.4, 2 недели</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4951147</td>\n",
       "      <td>2024-04-28 06:23:20</td>\n",
       "      <td>линзы acuvue</td>\n",
       "      <td>ACUVUE Контактные линзы, -3.75, 8.4, 2 недели</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>972605</td>\n",
       "      <td>2024-04-25 13:00:18</td>\n",
       "      <td>линзы acuvue</td>\n",
       "      <td>ACUVUE Контактные линзы, -3.75, 8.4, 2 недели</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>972605</td>\n",
       "      <td>2024-03-10 07:08:38</td>\n",
       "      <td>линзы acuvue</td>\n",
       "      <td>ACUVUE Контактные линзы, -3.75, 8.4, 2 недели</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           timestamp  search_query  \\\n",
       "0  9897711 2024-03-16 11:28:10         линзы   \n",
       "1  3666669 2024-04-15 13:40:39      линзы -4   \n",
       "2  4951147 2024-04-28 06:23:20  линзы acuvue   \n",
       "3   972605 2024-04-25 13:00:18  линзы acuvue   \n",
       "4   972605 2024-03-10 07:08:38  линзы acuvue   \n",
       "\n",
       "                                     product_name  \n",
       "0  ACUVUE Контактные линзы, -3.75, 8.4, 2 недели   \n",
       "1  ACUVUE Контактные линзы, -3.75, 8.4, 2 недели   \n",
       "2  ACUVUE Контактные линзы, -3.75, 8.4, 2 недели   \n",
       "3  ACUVUE Контактные линзы, -3.75, 8.4, 2 недели   \n",
       "4  ACUVUE Контактные линзы, -3.75, 8.4, 2 недели   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_product_positive_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50840f81-6962-442b-b5c8-894069a8d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fb59cee-8e43-4553-b065-235f7b276a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [01:04, 15442.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(query_product_positive_interactions.head(1_000_000).iterrows()):\n",
    "    data.append(\n",
    "        (\n",
    "            text_processor.process_text(row[1].search_query), \n",
    "            text_processor.process_text(row[1].product_name),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06daa3c6-88e5-4ff0-b081-746ffc27d1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('зелень свежая', 'укроп 75 г'),\n",
       " ('укроп', 'укроп 75 г'),\n",
       " ('зелень свежая', 'укроп 75 г'),\n",
       " ('зелень свежая', 'укроп 75 г'),\n",
       " ('укроп свежий', 'укроп 75 г')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c86a20e-377b-47ed-8a2c-cba82aae05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryDocDataset(Dataset):\n",
    "    def __init__(self, data: list[tuple[str, str]], tokenizer: Tokenizer, max_len: int = 32):\n",
    "        self.queries = [row[0] for row in data]\n",
    "        self.docs = [row[1] for row in data]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        query = self.queries[idx]\n",
    "        doc = self.docs[idx]\n",
    "\n",
    "        query_ids = self.tokenizer.encode(query).ids[:self.max_len]\n",
    "        doc_ids = self.tokenizer.encode(doc).ids[:self.max_len]\n",
    "\n",
    "        return {\n",
    "            \"query_ids\": torch.LongTensor(query_ids),\n",
    "            \"doc_ids\": torch.LongTensor(doc_ids),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    query_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        [x[\"query_ids\"] for x in batch], batch_first=True, padding_value=3\n",
    "    )\n",
    "    doc_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        [x[\"doc_ids\"] for x in batch], batch_first=True, padding_value=3\n",
    "    )\n",
    "    return {\"query_ids\": query_ids, \"doc_ids\": doc_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acd849a8-8a45-4611-985e-cee799edefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f226077-8c86-42fe-b628-01548de931a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSSM(\n",
       "  (embedding): Embedding(10000, 256, padding_idx=3)\n",
       "  (mlp): Sequential(\n",
       "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (7): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DSSM(vocab_size=tokenizer.get_vocab_size())\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d919fbf-d616-4884-8d7b-cb20d00323f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QueryDocDataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd8bc3d9-2845-4fff-822c-118d5c704663",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b769624c-9df6-4c57-bbd8-255be6e9eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce484fda-2cd5-4ed5-a355-14cd69e1beff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Loss: 4.6828\n",
      "Epoch: 0, Iteration: 1000, Loss: 3.9814\n",
      "Epoch: 0, Iteration: 2000, Loss: 3.9370\n",
      "Epoch: 0, Iteration: 3000, Loss: 3.9312\n",
      "Epoch: 0, Iteration: 4000, Loss: 3.9281\n",
      "Epoch: 0, Iteration: 5000, Loss: 3.9263\n",
      "Epoch: 0, Iteration: 6000, Loss: 3.9248\n",
      "Epoch: 0, Iteration: 7000, Loss: 3.9233\n",
      "Epoch: 1, Iteration: 0, Loss: 3.9764\n",
      "Epoch: 1, Iteration: 1000, Loss: 3.9199\n",
      "Epoch: 1, Iteration: 2000, Loss: 3.9189\n",
      "Epoch: 1, Iteration: 3000, Loss: 3.9188\n",
      "Epoch: 1, Iteration: 4000, Loss: 3.9181\n",
      "Epoch: 1, Iteration: 5000, Loss: 3.9185\n",
      "Epoch: 1, Iteration: 6000, Loss: 3.9192\n",
      "Epoch: 1, Iteration: 7000, Loss: 3.9176\n",
      "Epoch: 2, Iteration: 0, Loss: 3.9177\n",
      "Epoch: 2, Iteration: 1000, Loss: 3.9154\n",
      "Epoch: 2, Iteration: 2000, Loss: 3.9162\n",
      "Epoch: 2, Iteration: 3000, Loss: 3.9164\n",
      "Epoch: 2, Iteration: 4000, Loss: 3.9155\n",
      "Epoch: 2, Iteration: 5000, Loss: 3.9156\n",
      "Epoch: 2, Iteration: 6000, Loss: 3.9144\n",
      "Epoch: 2, Iteration: 7000, Loss: 3.9152\n",
      "Epoch: 3, Iteration: 0, Loss: 3.9257\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m---> 27\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      4\u001b[0m query_ids, doc_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m query_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m doc_vectors \u001b[38;5;241m=\u001b[39m model(doc_ids\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[1;32m      9\u001b[0m query_vectors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(query_vectors, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 26\u001b[0m, in \u001b[0;36mDSSM.forward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     22\u001b[0m input_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_ids)\n\u001b[1;32m     24\u001b[0m input_embeddings_pooled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(input_embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(input_ids\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m mlp_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_embeddings_pooled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(mlp_embeddings)\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/modules/normalization.py:202\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/3_10/lib/python3.10/site-packages/torch/nn/functional.py:2576\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2574\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2575\u001b[0m     )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_step(batch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    query_ids, doc_ids = batch[\"query_ids\"], batch[\"doc_ids\"]\n",
    "\n",
    "    query_vectors = model(query_ids.to(DEVICE))\n",
    "    doc_vectors = model(doc_ids.to(DEVICE))\n",
    "\n",
    "    query_vectors = torch.nn.functional.normalize(query_vectors, p=2, dim=1)\n",
    "    doc_vectors = torch.nn.functional.normalize(doc_vectors, p=2, dim=1)\n",
    "\n",
    "    scores = torch.matmul(query_vectors, doc_vectors.T)  # [batch_size, batch_size]\n",
    "\n",
    "    labels = torch.arange(len(scores), device=scores.device)\n",
    "\n",
    "    loss = loss_fn(scores, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_losses = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = train_step(batch)\n",
    "        train_losses.append(loss)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {sum(train_losses) / len(train_losses):.4f}\")\n",
    "            train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "484c13be-d86f-4b26-9aa6-ab318b855d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec_1, vec_2):\n",
    "    vec_1_normalized = torch.nn.functional.normalize(vec_1, p=2, dim=1)\n",
    "    vec_2_normalized = torch.nn.functional.normalize(vec_2, p=2, dim=1)\n",
    "    scores = torch.sum(vec_1_normalized * vec_2_normalized, dim=1)\n",
    "\n",
    "    return scores.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8bc1b08-8817-4815-bd8f-82f1dffb1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"творожный сыр\"\n",
    "doc = \"молоко\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5633428-e9bb-46dd-acf8-7480245d67de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model(torch.LongTensor([tokenizer.encode(query).ids]).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "351c402e-19ee-44bd-a11d-0cd404f3af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embedding = model(torch.LongTensor([tokenizer.encode(doc).ids]).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02f1857e-26e8-428f-9bee-cbc526e59dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06171335279941559"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(query_embedding, document_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f6af3-50bc-4ae7-a17f-d5147d4def0b",
   "metadata": {},
   "source": [
    "## ANN index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "707d5ead-0c85-4986-ae65-aeab9c07cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_names = [x.document_name for x in documents_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4ab7331-55c3-4532-bd01-039cf8903613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['модуль сменный фильтрующий аквафор кн 208731',\n",
       " 'водоочиститель аквафор модель кристалл н 205963 с краном',\n",
       " 'развиваем мышление 2 3 года земцова ольга']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8d03bfb-b831-4a65-93de-25129daf555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238428/238428 [01:32<00:00, 2566.70it/s]\n"
     ]
    }
   ],
   "source": [
    "def embed_texts(texts, model, tokenizer, max_len=32):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts):\n",
    "            text_ids = tokenizer.encode(text).ids[:max_len]\n",
    "            text_ids = torch.tensor(text_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "            text_embedding = model(text_ids)\n",
    "            embeddings.append(text_embedding.squeeze(0).cpu().numpy())\n",
    "    return np.stack(embeddings)\n",
    "\n",
    "\n",
    "doc_embeddings = embed_texts(document_names, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84068a3c-40a4-41fc-9d3f-2f990e12648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = doc_embeddings.shape[1]\n",
    "index = hnswlib.Index(space=\"cosine\", dim=dim)\n",
    "\n",
    "index.init_index(max_elements=len(documents), ef_construction=200, M=16)\n",
    "index.add_items(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbdc9927-5faa-437d-a139-fcc840363ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 719.06it/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"сыр сливочный\"\n",
    "query_embedding = embed_texts([query], model, tokenizer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abca3ead-51df-4b08-b263-0c3da6254531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(document_id=149171036, document_name='Сыр творожный сливочный 60% 150 г, Almette') (Score: 0.9999899864196777)\n",
      "Document(document_id=291544604, document_name='Сыр творожный сливочный 150 г, Almette') (Score: 0.9999895095825195)\n",
      "Document(document_id=170339265, document_name='Сыр творожный Violette, сливочный, 70 %, 140 г') (Score: 0.9999889135360718)\n",
      "Document(document_id=194534557, document_name='Сыр Ламбер \"Гауда\", 45%, кусок, 180 г') (Score: 0.9999889135360718)\n",
      "Document(document_id=142583602, document_name='Сыр полутвердый Сливочный 250 г, Laplandia, нарезка') (Score: 0.9999886751174927)\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "labels, distances = index.knn_query(query_embedding, k=k)\n",
    "\n",
    "for i, (label, dist) in enumerate(zip(labels[0], distances[0])):\n",
    "    print(f\"{documents[label]} (Score: {1 - dist})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e1beb-7226-470a-bc3d-00590f69bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSMRetriever:\n",
    "    def __init__(self, model, tokenizer, documents, document_names):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.documents = documents\n",
    "        self.document_names = document_names\n",
    "        \n",
    "        self.dim = model.output_dim\n",
    "        self.index = hnswlib.Index(space=\"cosine\", dim=self.dim)\n",
    "        self.index.init_index(max_elements=len(self.document_names), ef_construction=200, M=16)\n",
    "        \n",
    "        doc_embeddings = embed_texts(self.document_names, model, tokenizer)\n",
    "        self.index.add_items(doc_embeddings)\n",
    "    \n",
    "    def search(self, query, k=5):\n",
    "        query_embedding = embed_texts([query], self.model, self.tokenizer)[0]\n",
    "        labels, _ = self.index.knn_query(query_embedding, k=k)\n",
    "        return [self.documents[label] for label in labels[0]]\n",
    "\n",
    "\n",
    "retriever = DSSMRetriever(model, tokenizer, documents, document_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee557b93-2fc4-4d36-8261-c95a2715f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.search(\"корм для собак\", k=10)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67d540-7615-4f51-bd27-64bbd82b95b0",
   "metadata": {},
   "source": [
    "## ColBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbf9b6-66b6-4c87-aaae-aa90a1674e17",
   "metadata": {},
   "source": [
    "![title](colbert.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab4552ad-8de6-4b48-ba33-79c0a6bed092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColBERT:\n",
    "    def __init__(self, model_name: str = \"cointegrated/rubert-tiny\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "        self.dim = self.model.config.hidden_size\n",
    "        self.model.eval()\n",
    "        \n",
    "    def encode(self, texts):\n",
    "        inputs = self.tokenizer(\n",
    "            texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\",\n",
    "            max_length=64\n",
    "        ).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.cpu()\n",
    "    \n",
    "    def compute_scores(self, query_emb, doc_emb):\n",
    "        query_emb = torch.nn.functional.normalize(query_emb, p=2, dim=-1)\n",
    "        doc_emb = torch.nn.functional.normalize(doc_emb, p=2, dim=-1)\n",
    "        \n",
    "        sim = torch.bmm(query_emb, doc_emb.transpose(1, 2))\n",
    "        \n",
    "        return torch.max(sim, dim=-1).values.sum(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c7980bb-79b6-467c-aec2-30dc5b5eadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissIndex:\n",
    "    def __init__(self, dim):\n",
    "        self.index = faiss.IndexFlatIP(dim)\n",
    "        \n",
    "    def add_docs(self, embeddings):\n",
    "        doc_vectors = embeddings.mean(dim=1).numpy()\n",
    "        self.index.add(doc_vectors)\n",
    "        \n",
    "    def search(self, query_emb, k=5):\n",
    "        query_vector = query_emb.mean(dim=1).numpy()\n",
    "        distances, labels = self.index.search(query_vector, k=k)\n",
    "        return labels, distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91f90cde-4d0d-42ff-ad94-501ea8043005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dandrosov/venvs/3_10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "colbert = ColBERT()\n",
    "index = FaissIndex(dim=colbert.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e08702c-574b-4397-b2e4-810193805b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_names = [x.document_name for x in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38d197e2-1e3a-4915-b183-bbe7b80ef2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:30<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "doc_embeddings = []\n",
    "for i in tqdm(range(0, 240_000, 10_000)):\n",
    "    doc_embeddings.append(colbert.encode(document_names[i:i+10000]))\n",
    "doc_embeddings = torch.cat(doc_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfc99269-05ef-4fe6-920b-bb1bd3d99cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add_docs(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86ba34b4-62bf-4517-9620-112fc2ec709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"молоко\"\n",
    "query_embedding = colbert.encode([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27de635d-3168-4421-a5fa-7e4b7311da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(document_id=441379467, document_name='Авокадо') (Score: 144.330)\n",
      "Document(document_id=196062760, document_name='Кукла') (Score: 142.064)\n",
      "Document(document_id=20365946, document_name='Репка') (Score: 141.719)\n",
      "Document(document_id=1539615715, document_name='Чулки') (Score: 141.320)\n",
      "Document(document_id=567427685, document_name='Зеркало') (Score: 141.117)\n"
     ]
    }
   ],
   "source": [
    "labels, scores = index.search(query_embedding, k=5)\n",
    "\n",
    "for i, (label, score) in enumerate(zip(labels[0], scores[0])):\n",
    "    print(f\"{documents[label]} (Score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e0591-3991-485a-8788-f0eada3ccf19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59d434-d1a5-409d-806f-fd21de1a1a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef199bc-df78-4e7f-8c8d-fa249d7e20e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1f1b5ab-6678-48a7-8b79-e7695292f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name: str = \"cointegrated/rubert-tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7201aa41-1f5f-444f-8e3e-ac714dacd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42fe24cd-c9f4-458a-96ce-26b891b5ae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   324, 20879,  1597,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\n",
    "    [\"молоко\"], \n",
    "    padding=True, \n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\",\n",
    "    max_length=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e8196-b246-4f07-b08e-7ed95e2a3f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
